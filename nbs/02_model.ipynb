{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: model\n",
    "output-file: model.html\n",
    "description: model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n",
    "\n",
    "> A simple API for creating and using playing cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from fastcore.utils import *\n",
    "from tinypytorch.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        self.args = args # it will call self.inp, and self.targ...\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    \n",
    "    def forward(self):\n",
    "        raise Exception(\"Not implemented\")\n",
    "    \n",
    "    def backward(self):\n",
    "        self.bwd(self.out, *self.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ReLU(Module):\n",
    "    # def __call__(self, inp: 'input'):\n",
    "    #     self.inp = inp\n",
    "    #     self.out = inp.clamp_min(0.) - 0.5\n",
    "    #     return self.out\n",
    "    \n",
    "    def forward(self, inp: 'input'):\n",
    "        return inp.clamp_min(0.) - 0.5\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = (inp > 0).float() * out.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MSE(Module):\n",
    "    \n",
    "#     def __call__(self, inp: 'input', targ: 'target'):\n",
    "#         self.inp = inp\n",
    "#         self.targ = targ\n",
    "        \n",
    "#         print(\"MSE.forward\")\n",
    "#         print(f\"inp.shape={inp.shape}\")\n",
    "#         print(f\"inp.squeeze().shape={inp.squeeze(-1).shape}\")\n",
    "#         print(f\"targ.shape={targ.shape}\")\n",
    "        \n",
    "#         temp = (inp.squeeze() - targ)\n",
    "#         print(f\"temp={temp}\")\n",
    "        \n",
    "#         return torch.pow(temp, 2).mean()\n",
    "    \n",
    "    def forward(self, inp, targ):\n",
    "        \n",
    "        # print(\"MSE.forward\")\n",
    "        # print(f\"inp.shape={inp.shape}\")\n",
    "        # print(f\"inp.squeeze().shape={inp.squeeze(-1).shape}\")\n",
    "        # print(f\"targ.shape={targ.shape}\")\n",
    "        \n",
    "        temp = (inp.squeeze() - targ)\n",
    "        # print(f\"temp={temp}\")\n",
    "        \n",
    "        return torch.pow(temp, 2).mean()\n",
    "\n",
    "    def bwd(self, out, inp, targ):\n",
    "        inp.g = 2*(inp.squeeze() - targ).unsqueeze(-1) / targ.shape[0]\n",
    "        \n",
    "    # def backward(self):\n",
    "    #     self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = MSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = torch.randn(size=[4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6239],\n",
       "        [ 1.0623],\n",
       "        [-1.1395],\n",
       "        [-0.2901]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_b = torch.rand_like(tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7852],\n",
       "        [0.1587],\n",
       "        [0.6888],\n",
       "        [0.3324]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2752)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse.forward(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def log_softmax(x):\n",
    "    return (x.exp()/(x.exp().sum(-1, keepdim=True))).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-entropy is a derivation from Kull-back divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Negative Log Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ = torch.tensor([5, 0, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pred = torch.tensor([[0, 1, 2], [5, 0, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [5, 0, 4]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[[0, 1], [2, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def nll(inp: 'input', targ: 'target'):\n",
    "    return -inp[range(targ.shape[0]), targ].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cross_entropy(pred: 'prediction', targ: 'target'):\n",
    "    sm_pred = log_softmax(pred)\n",
    "    return nll(sm_pred, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.tensor([[0, 1, 2], [5, 0, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ = torch.tensor([2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8629)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(pred, targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class Lin():\n",
    "#     def __init__(self, w, b):\n",
    "#         self.w = w\n",
    "#         self.b = b\n",
    "    \n",
    "#     def __call__(self, inp):\n",
    "#         self.inp = inp\n",
    "#         self.out = inp @ self.w + self.b\n",
    "#         return self.out\n",
    "    \n",
    "#     def backward(self):\n",
    "#         self.inp.g = self.out.g @ self.w.t()\n",
    "#         self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
    "#         self.b.g = self.out.g.sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The gradient of Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Lin(Module):\n",
    "    def __init__(self, w: 'weight', b: 'bias'):\n",
    "        self.w, self.b = w, b\n",
    "    \n",
    "    # def __call__(self, inp):\n",
    "    #     self.inp = inp\n",
    "    #     self.out = inp @ self.w + self.b\n",
    "    #     return self.out\n",
    "    \n",
    "    def forward(self, inp: 'input'):\n",
    "        print(\"Lin.forward\")\n",
    "        print(f\"inp={inp.shape}\")\n",
    "        print(f\"w={self.w.shape}\")\n",
    "        print(f\"b={self.b.shape}\")\n",
    "        \n",
    "        output = inp @ self.w + self.b\n",
    "        print(f\"output.shape={output.shape}\")\n",
    "        return output\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        # self.w.g = torch.einsum(\"bi,bj->ij\", inp, out.g)\n",
    "        self.w.g = inp.t() @ out.g\n",
    "        # self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
    "        self.b.g = out.g.sum(0)\n",
    "        #self.w.g = torch.einsum(\"bi,bj->ij\", self.inp, self.out.g)\n",
    "        #self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class Model():\n",
    "#     def __init__(self, m, nh: \"number of hidden\"):\n",
    "#         self.m, self.nh = m, nh\n",
    "    \n",
    "#     def forward(self, xb: 'training batch'):\n",
    "#         w1, b1, w2, b2 = self.initialize_parameters()\n",
    "#         l1 = Lin(xb, w1, b1)\n",
    "#         l2 = ReLU(l1)\n",
    "#         l3 = Lin(l2, w2, b2)\n",
    "        \n",
    "#         return l3\n",
    "    \n",
    "#     def initialize_parameters(self):\n",
    "#         # kaiming init / he init for relu\n",
    "#         w1 = torch.randn(self.m, self.nh)*math.sqrt(2./self.m)\n",
    "#         b1 = torch.zeros(self.nh)\n",
    "#         w2 = torch.randn(self.nh, 1)/math.sqrt(self.nh)\n",
    "#         b2 = torch.zeros\n",
    "#         return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class Model():\n",
    "#     def __init__(self, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class Model():\n",
    "#     def __init__(self, w1, b1, w2, b2):\n",
    "#         self.layers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# def get_model():\n",
    "#     model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def initialize_parameters(m, nh: \"number of hidden layers\"):\n",
    "    # kaiming init / he init for relu\n",
    "    w1 = torch.randn(m, nh)*math.sqrt(2./m)\n",
    "    b1 = torch.zeros(nh)\n",
    "    w2 = torch.randn(nh, 1)/math.sqrt(nh)\n",
    "    b2 = torch.zeros(1)\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Model():\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Lin(w1, b1), ReLU(), Lin(w2, b2)]\n",
    "        self.loss = MSE()\n",
    "    \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers:\n",
    "            print(\"Model.__call__\")\n",
    "            print(f\"l={l}\")\n",
    "            x = l(x)\n",
    "            print(f\"x.shape={x.shape}\")\n",
    "        \n",
    "        #assert x.shape==torch.Size([targ.shape[0],1])\n",
    "        \n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers):\n",
    "            l.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train(epochs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def accuracy(out, yb):\n",
    "    return (torch.argmax(out, dim=1) == yb).float().mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
