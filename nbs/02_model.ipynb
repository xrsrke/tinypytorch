{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: model\n",
    "output-file: model.html\n",
    "description: model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n",
    "\n",
    "> A simple API for creating and using playing cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from fastcore.utils import *\n",
    "from tinypytorch.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        self.args = args # it will call self.inp, and self.targ...\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    \n",
    "    def forward(self):\n",
    "        raise Exception(\"Not implemented\")\n",
    "    \n",
    "    def backward(self):\n",
    "        self.bwd(self.out, *self.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ReLU(Module):\n",
    "    def __call__(self, inp: 'input'):\n",
    "        self.inp = inp\n",
    "        self.out = inp.clamp_min(0.) - 0.5\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = (self.inp > 0).float() * self.out.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The gradient of MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MSE(Module):\n",
    "    \n",
    "    def __call__(self, inp: 'input', targ: 'target'):\n",
    "        self.inp = inp\n",
    "        self.targ = targ\n",
    "        \n",
    "        print(\"MSE.forward\")\n",
    "        print(f\"inp.shape={inp.shape}\")\n",
    "        print(f\"inp.squeeze().shape={inp.squeeze(-1).shape}\")\n",
    "        print(f\"targ.shape={targ.shape}\")\n",
    "        \n",
    "        temp = (inp.squeeze() - targ)\n",
    "        print(f\"temp={temp}\")\n",
    "        \n",
    "        return torch.pow(temp, 2).mean()\n",
    "\n",
    "    def backward(self):\n",
    "        self.inp.g = 2*(self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]\n",
    "        \n",
    "    # def backward(self):\n",
    "    #     self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = MSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = torch.randn(size=[4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6773],\n",
       "        [-0.5086],\n",
       "        [-1.2705],\n",
       "        [-0.6457]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_b = torch.rand_like(tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0966],\n",
       "        [0.3387],\n",
       "        [0.7229],\n",
       "        [0.2761]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE.forward\n",
      "inp.shape=torch.Size([4, 1])\n",
      "inp.squeeze().shape=torch.Size([4])\n",
      "targ.shape=torch.Size([4, 1])\n",
      "temp=tensor([[-2.8847, -1.7574, -0.0708, -1.0113],\n",
      "        [-3.0568, -1.9296, -0.2430, -1.1835],\n",
      "        [-2.6710, -1.5438,  0.1428, -0.7976],\n",
      "        [-2.5294, -1.4022,  0.2844, -0.6561]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.8759)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse.forward(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class Lin():\n",
    "#     def __init__(self, w, b):\n",
    "#         self.w = w\n",
    "#         self.b = b\n",
    "    \n",
    "#     def __call__(self, inp):\n",
    "#         self.inp = inp\n",
    "#         self.out = inp @ self.w + self.b\n",
    "#         return self.out\n",
    "    \n",
    "#     def backward(self):\n",
    "#         self.inp.g = self.out.g @ self.w.t()\n",
    "#         self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
    "#         self.b.g = self.out.g.sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The gradient of Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Lin(Module):\n",
    "    def __init__(self, w: 'weight', b: 'bias'):\n",
    "        self.w, self.b = w, b\n",
    "    \n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp @ self.w + self.b\n",
    "        return self.out\n",
    "    \n",
    "#     def forward(self, inp: 'input'):\n",
    "#         print(\"Lin.forward\")\n",
    "#         print(f\"inp={inp.shape}\")\n",
    "#         print(f\"w={self.w.shape}\")\n",
    "#         print(f\"b={self.b.shape}\")\n",
    "        \n",
    "#         output = inp @ self.w + self.b\n",
    "#         print(f\"output.shape={output.shape}\")\n",
    "#         return output\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = self.out.g @ self.w.t()\n",
    "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
    "        self.b.g = self.out.g.sum(0)\n",
    "        #self.w.g = torch.einsum(\"bi,bj->ij\", self.inp, self.out.g)\n",
    "        #self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class Model():\n",
    "#     def __init__(self, m, nh: \"number of hidden\"):\n",
    "#         self.m, self.nh = m, nh\n",
    "    \n",
    "#     def forward(self, xb: 'training batch'):\n",
    "#         w1, b1, w2, b2 = self.initialize_parameters()\n",
    "#         l1 = Lin(xb, w1, b1)\n",
    "#         l2 = ReLU(l1)\n",
    "#         l3 = Lin(l2, w2, b2)\n",
    "        \n",
    "#         return l3\n",
    "    \n",
    "#     def initialize_parameters(self):\n",
    "#         # kaiming init / he init for relu\n",
    "#         w1 = torch.randn(self.m, self.nh)*math.sqrt(2./self.m)\n",
    "#         b1 = torch.zeros(self.nh)\n",
    "#         w2 = torch.randn(self.nh, 1)/math.sqrt(self.nh)\n",
    "#         b2 = torch.zeros\n",
    "#         return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class Model():\n",
    "#     def __init__(self, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class Model():\n",
    "#     def __init__(self, w1, b1, w2, b2):\n",
    "#         self.layers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# def get_model():\n",
    "#     model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def initialize_parameters(m, nh: \"number of hidden layers\"):\n",
    "    # kaiming init / he init for relu\n",
    "    w1 = torch.randn(m, nh)*math.sqrt(2./m)\n",
    "    b1 = torch.zeros(nh)\n",
    "    w2 = torch.randn(nh, 1)/math.sqrt(nh)\n",
    "    b2 = torch.zeros(1)\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Model():\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Lin(w1, b1), ReLU(), Lin(w2, b2)]\n",
    "        self.loss = MSE()\n",
    "    \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers:\n",
    "            print(\"Model.__call__\")\n",
    "            print(f\"l={l}\")\n",
    "            x = l(x)\n",
    "            print(f\"x.shape={x.shape}\")\n",
    "        \n",
    "        #assert x.shape==torch.Size([targ.shape[0],1])\n",
    "        \n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers):\n",
    "            l.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train(epochs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def accuracy(out, yb):\n",
    "    return (torch.argmax(out, dim=1) == yb).float().mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
