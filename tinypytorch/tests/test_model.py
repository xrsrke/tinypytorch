# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/02_tests.test_model.ipynb.

# %% auto 0
__all__ = ['A', 'B', 'x_train', 'y_train', 'x_valid', 'y_valid', 'bs', 'xb', 'yb', 'n_in', 'nh', 'n_out', 'model',
           'test_intialize_parameters_should_return_true', 'test_linear_forward_pass', 'test_model_params_shape',
           'test_model_forward_pass', 'test_model_backward_pass', 'test_mse_forward_pass', 'test_mse_backward_pass',
           'test_log_softmax_forward_pass', 'test_nll', 'test_cross_entropy_backward_pass', 'test_relu_forward_pass',
           'test_relu_backward_pass']

# %% ../../nbs/02_tests.test_model.ipynb 1
import torch
import torch.nn as nn
import torch.nn.functional as F

from fastcore.utils import *
from ..core import *
from ..data import get_local_data
from ..model import Lin, ReLU, MSE, initialize_parameters, log_softmax, nll, cross_entropy, Model

import pytest

# %% ../../nbs/02_tests.test_model.ipynb 4
A = torch.arange(start=-4, end=8, dtype=torch.float)

# %% ../../nbs/02_tests.test_model.ipynb 5
A = torch.reshape(A, (4, 3))

# %% ../../nbs/02_tests.test_model.ipynb 7
B = torch.arange(13, 25, dtype=torch.float)

# %% ../../nbs/02_tests.test_model.ipynb 8
B = torch.reshape(B, (4, 3))

# %% ../../nbs/02_tests.test_model.ipynb 11
x_train, y_train, x_valid, y_valid = get_local_data()

# %% ../../nbs/02_tests.test_model.ipynb 12
bs = 64

# %% ../../nbs/02_tests.test_model.ipynb 14
xb = x_train[0:bs]
yb = y_train[0:bs]

# %% ../../nbs/02_tests.test_model.ipynb 16
n_in, nh, n_out = 784, 50, 10

# %% ../../nbs/02_tests.test_model.ipynb 18
@pytest.fixture
def model():
    return Model(n_in, nh, n_out)

# %% ../../nbs/02_tests.test_model.ipynb 19
def test_intialize_parameters_should_return_true():
    
    m = 5 # number of rows
    nh = 3 # number of hidden layers
    w1, b1, w2, b2 = initialize_parameters(m=m, nh=nh)
    assert w1.shape == (m, nh)
    assert b1.shape == (nh,)
    assert w2.shape == (nh, 1)
    assert b2.shape == (1,)

# %% ../../nbs/02_tests.test_model.ipynb 20
def test_linear_forward_pass():
    pass

# %% ../../nbs/02_tests.test_model.ipynb 22
def test_model_params_shape(model):
    assert model.w1.shape == (n_in, nh)
    assert model.b1.shape == (nh,)
    assert model.w2.shape == (nh, n_out)
    assert model.b2.shape == (n_out,)

# %% ../../nbs/02_tests.test_model.ipynb 23
# TODO: fix
def test_model_forward_pass(model):
    assert model(xb).shape == nn.Linear(n_in, n_out)(xb).shape

# %% ../../nbs/02_tests.test_model.ipynb 24
def test_model_backward_pass():
    pass

# %% ../../nbs/02_tests.test_model.ipynb 27
def test_mse_forward_pass():
    
    output = MSE().forward(A, B)
    result = F.mse_loss(A, B)
    
    assert is_near_tensor(output, result) == True

# %% ../../nbs/02_tests.test_model.ipynb 28
def test_mse_backward_pass():
    pass

# %% ../../nbs/02_tests.test_model.ipynb 30
@pytest.mark.parametrize(("test_input"), (A, xb))
def test_log_softmax_forward_pass(test_input):
    assert is_near_tensor(log_softmax(A), F.log_softmax(A, dim=1)) == True

# %% ../../nbs/02_tests.test_model.ipynb 36
@pytest.mark.parametrize(
    ("test_input", "target"),
    ((torch.tensor([1, 0]), torch.tensor([[0, 1, 2], [5, 0, 4]], dtype=torch.float)))
)
def test_nll(test_input, target):
    output = nll(test_input, target)
    result = F.nll_loss(F.test_input, target)
    assert is_near_tensor(output, result) == True

# %% ../../nbs/02_tests.test_model.ipynb 60
def test_cross_entropy_backward_pass():
    pred = torch.tensor([[0, 1, 2], [5, 0, 4]], dtype=torch.float)
    targ = torch.tensor([2, 1])
    
    assert cross_entropy(pred, targ) == F.cross_entropy(pred, targ)

# %% ../../nbs/02_tests.test_model.ipynb 63
def test_relu_forward_pass():
    
    output = ReLU().forward(A)
    result = F.relu(A) - 0.5
    assert is_near_tensor(output, result) == True

# %% ../../nbs/02_tests.test_model.ipynb 64
def test_relu_backward_pass():
    pass
